{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPvfDg59FhhQLc6FJLjTFeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliyaBadmaeva/PDP/blob/main/Badmaeva_A_A__PDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zD6rA4UVc7v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
      ],
      "metadata": {
        "id": "pM6Wr70jQKNk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYQXghj0mnWF",
        "outputId": "35dc4f56-58dd-44ce-8ab7-3f28f8167b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (3.10.0)\r\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (1.3.1)\r\n",
            "Requirement already satisfied: cycler>=0.10 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (0.11.0)\r\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (4.55.3)\r\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (1.4.8)\r\n",
            "Requirement already satisfied: numpy>=1.23 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (2.2.5)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (24.2)\r\n",
            "Requirement already satisfied: pillow>=8 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (11.1.0)\r\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (3.2.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh930bmImx6F",
        "outputId": "09eebbab-d591-445c-cf4c-4c572a1d90ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from scikit-learn) (2.2.5)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Downloading scipy-1.15.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.7.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Downloading scipy-1.15.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn]\n",
            "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "wnmW7J50EbwS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izM0FmeQKQhv",
        "outputId": "f9533f48-43ba-4e9a-c5c4-de9bb0bfbb12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\r\n",
            "Version: 4.52.4\r\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\r\n",
            "Home-page: https://github.com/huggingface/transformers\r\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\r\n",
            "Author-email: transformers@huggingface.co\r\n",
            "License: Apache 2.0 License\r\n",
            "Location: /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages\r\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\r\n",
            "Required-by: \r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "from transformers.optimization import get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "wB-QwDzmHMYW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "QZq0moi5crM8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ссылка на датасет на Гитхабе\n",
        "#IMDB = 'https://raw.githubusercontent.com/AliyaBadmaeva/imdb/master/IMDB_Dataset.zip'"
      ],
      "metadata": {
        "id": "aJYn6kzFdQjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Датасет взяла тут:https://www.kaggle.com/datasets/sarath02003/multiclass-sentiment-analysis?select=val_df.csv\n",
        "train = pd.read_csv('train_df.csv')  # чтение данных с помощью библиотеки Pandas\n",
        "test = pd.read_csv('test_df.csv')\n",
        "val = pd.read_csv('val_df.csv')\n",
        "\n",
        "train.head(10)  # Первые 10 строк датасета"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "UeafEJwNdvVE",
        "outputId": "f7c3c910-a471-4451-dbe1-0c092cdc708e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text  label sentiment\n",
              "0   9536                    Cooking microwave pizzas, yummy      2  positive\n",
              "1   6135  Any plans of allowing sub tasks to show up in ...      1   neutral\n",
              "2  17697   I love the humor, I just reworded it. Like sa...      2  positive\n",
              "3  14182                       naw idk what ur talkin about      1   neutral\n",
              "4  17840          That sucks to hear. I hate days like that      0  negative\n",
              "5   3655   Umm yeah. That`s probably a pretty good note ...      2  positive\n",
              "6    719                              whatever do you mean?      1   neutral\n",
              "7  22823   That would panic me a little!  Maybe you can ...      0  negative\n",
              "8   4869               Is sad when people`s phones are dead      0  negative\n",
              "9    793                                          sad face.      0  negative"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9536</td>\n",
              "      <td>Cooking microwave pizzas, yummy</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6135</td>\n",
              "      <td>Any plans of allowing sub tasks to show up in ...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17697</td>\n",
              "      <td>I love the humor, I just reworded it. Like sa...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14182</td>\n",
              "      <td>naw idk what ur talkin about</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17840</td>\n",
              "      <td>That sucks to hear. I hate days like that</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3655</td>\n",
              "      <td>Umm yeah. That`s probably a pretty good note ...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>719</td>\n",
              "      <td>whatever do you mean?</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>22823</td>\n",
              "      <td>That would panic me a little!  Maybe you can ...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4869</td>\n",
              "      <td>Is sad when people`s phones are dead</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>793</td>\n",
              "      <td>sad face.</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "g_BNRKI1Jctp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "84a1c7d6-e76c-4581-f1cd-6d1cbb8feb67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text  label sentiment\n",
              "0   9235                         getting cds ready for tour      1   neutral\n",
              "1  16790   MC, happy mother`s day to your mom ;).. love yah      2  positive\n",
              "2  24840  A year from now is graduation....i am pretty s...      0  negative\n",
              "3  20744              because you had chips and sale w/o me      1   neutral\n",
              "4   6414          Great for organising my work life balance      2  positive"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9235</td>\n",
              "      <td>getting cds ready for tour</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16790</td>\n",
              "      <td>MC, happy mother`s day to your mom ;).. love yah</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24840</td>\n",
              "      <td>A year from now is graduation....i am pretty s...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20744</td>\n",
              "      <td>because you had chips and sale w/o me</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6414</td>\n",
              "      <td>Great for organising my work life balance</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hWYj-qWLsjJW",
        "outputId": "b1d90344-09bb-4c44-e286-ea1d0dcd2805"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text  label sentiment\n",
              "0    317  Laying in bed til workkk... Oh the life. Defin...      0  negative\n",
              "1  24292   ooohhh imma need you to get on that asap love...      2  positive\n",
              "2   3513   Thanks! I love it they have a video, so you d...      2  positive\n",
              "3   4322     I left my ipod in the car so now its all warm.      2  positive\n",
              "4   6203  Great app. Only complaint is that I'd like the...      2  positive"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>317</td>\n",
              "      <td>Laying in bed til workkk... Oh the life. Defin...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24292</td>\n",
              "      <td>ooohhh imma need you to get on that asap love...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3513</td>\n",
              "      <td>Thanks! I love it they have a video, so you d...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4322</td>\n",
              "      <td>I left my ipod in the car so now its all warm.</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6203</td>\n",
              "      <td>Great app. Only complaint is that I'd like the...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()  # типы данных для каждого их признаков и количество строк"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhmzdQWNd6-M",
        "outputId": "a4ff33ab-2ae4-4206-ca43-9620668f656f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31232 entries, 0 to 31231\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         31232 non-null  int64 \n",
            " 1   text       31232 non-null  object\n",
            " 2   label      31232 non-null  int64 \n",
            " 3   sentiment  31232 non-null  object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 976.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxV4sWvust5e",
        "outputId": "4ecfc83a-fe3f-4008-f37d-322638b64467"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5206 entries, 0 to 5205\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         5206 non-null   int64 \n",
            " 1   text       5205 non-null   object\n",
            " 2   label      5206 non-null   int64 \n",
            " 3   sentiment  5206 non-null   object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 162.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O2MgFOEsxeu",
        "outputId": "470cea08-84cb-4387-c672-d8404341292e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5205 entries, 0 to 5204\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         5205 non-null   int64 \n",
            " 1   text       5205 non-null   object\n",
            " 2   label      5205 non-null   int64 \n",
            " 3   sentiment  5205 non-null   object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 162.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe()  # статистические данные"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "bUpyUM0Se2ll",
        "outputId": "29482e00-3088-46b8-f2c9-2575e3c800a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id         label\n",
              "count  31232.000000  31232.000000\n",
              "mean   10576.775359      1.043961\n",
              "std     8010.753795      0.790636\n",
              "min        0.000000      0.000000\n",
              "25%     3476.000000      0.000000\n",
              "50%     8662.000000      1.000000\n",
              "75%    17071.500000      2.000000\n",
              "max    27480.000000      2.000000"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31232.000000</td>\n",
              "      <td>31232.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10576.775359</td>\n",
              "      <td>1.043961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8010.753795</td>\n",
              "      <td>0.790636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3476.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8662.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17071.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>27480.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['label'].value_counts()  # количество данных в целевом признаке"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4RwAzAifDPO",
        "outputId": "2b15cbcc-1b16-4882-d038-3a1bbb447969"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    11649\n",
              "2    10478\n",
              "0     9105\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMoyTLAns9kF",
        "outputId": "b41bade1-ccf9-44e8-a124-a33aa73b9275"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    1930\n",
              "2    1730\n",
              "0    1546\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoiFMi0etCOX",
        "outputId": "73a2ce54-1713-4131-8348-13948a161ab9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    1928\n",
              "2    1760\n",
              "0    1517\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# удалим нулевые значения по наличию в одном из 2х столбцах, чтобы не было потом проблем с созданием тензоров из списка строк\n",
        "val.dropna(axis=0, how='any', subset=['text', 'label'], inplace=True)\n",
        "train.dropna(axis=0, how='any',subset=['text', 'label'], inplace=True)\n",
        "test.dropna(axis=0, how='any', subset=['text', 'label'], inplace=True)"
      ],
      "metadata": {
        "id": "qOSExQyw608Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urxHjqSk7Qjm",
        "outputId": "3944dd2c-d5dc-4d1b-e110-00db310a1d1f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31232 entries, 0 to 31231\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         31232 non-null  int64 \n",
            " 1   text       31232 non-null  object\n",
            " 2   label      31232 non-null  int64 \n",
            " 3   sentiment  31232 non-null  object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 976.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mBPGvkQ7Vid",
        "outputId": "a1af6f6d-ecf2-465b-df0e-913aeec02af3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5205 entries, 0 to 5205\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         5205 non-null   int64 \n",
            " 1   text       5205 non-null   object\n",
            " 2   label      5205 non-null   int64 \n",
            " 3   sentiment  5205 non-null   object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 203.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTCshp1X7Z6e",
        "outputId": "fd44f0ba-5843-4d25-8a54-d2624b0ecd71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5205 entries, 0 to 5204\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         5205 non-null   int64 \n",
            " 1   text       5205 non-null   object\n",
            " 2   label      5205 non-null   int64 \n",
            " 3   sentiment  5205 non-null   object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 162.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.duplicated().sum()  # количество дублей"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKr7a2JJfNLm",
        "outputId": "f5eace69-54c9-4a1d-fc22-780934ad98bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.duplicated().sum()  # количество дублей"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veswEd3PtEEN",
        "outputId": "b60d0a73-c4a3-4fe4-a6f8-4625cc104aa4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val.duplicated().sum()  # количество дублей"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dy2xeDUtHTO",
        "outputId": "bb86aff5-96d3-4b90-83be-b8ca56723bbc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!pip install --upgrade nbformat\n",
        "!pip install --upgrade nbconvert'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juRfJ8AnnQ_g",
        "outputId": "8f016134-4e8f-4143-80d2-b158b9e99b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!pip install --upgrade nbformat\\n!pip install --upgrade nbconvert'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['id','sentiment'],axis=1,inplace=True)\n",
        "test.drop(['id','sentiment'],axis=1,inplace=True)\n",
        "val.drop(['id','sentiment'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "wqzN8hQtx2gR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rev = [len(t.split()) for t in train['text']]\n",
        "plt.hist(train_rev, bins=20)"
      ],
      "metadata": {
        "id": "K-DBTuSsZPmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "outputId": "ac1d5bb1-d13d-4e5f-bfa9-bc64313e727e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.2604e+04, 6.0550e+03, 1.1560e+03, 6.4400e+02, 6.5400e+02,\n",
              "        6.8000e+01, 2.4000e+01, 8.0000e+00, 8.0000e+00, 7.0000e+00,\n",
              "        2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
              " array([  1. ,  20.5,  40. ,  59.5,  79. ,  98.5, 118. , 137.5, 157. ,\n",
              "        176.5, 196. , 215.5, 235. , 254.5, 274. , 293.5, 313. , 332.5,\n",
              "        352. , 371.5, 391. ]),\n",
              " <BarContainer object of 20 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "metadata": {
        "id": "RcaWUbxpvIb9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload it with the huggingface tokenizers library\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', lowercase=False)\n",
        "tokenizer.save_pretrained('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfzkdd_ax2cn",
        "outputId": "3f60d1f9-6c62-4331-b0c4-04fa928dfc9c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./tokenizer_config.json',\n",
              " './special_tokens_map.json',\n",
              " './vocab.txt',\n",
              " './added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.text\n",
        "X_test = test.text\n",
        "X_val = val.text\n",
        "\n",
        "y_train = train.label\n",
        "y_test = test.label\n",
        "y_val = val.label"
      ],
      "metadata": {
        "id": "sq2Dm-Hx25Ie"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 100"
      ],
      "metadata": {
        "id": "0C5Q6OJA1WgN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "encodings_train = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=MAX_LEN, return_tensors='pt')\n",
        "encodings_val = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=MAX_LEN, return_tensors='pt')\n",
        "encodings_test = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=MAX_LEN, return_tensors='pt')"
      ],
      "metadata": {
        "id": "fTjVjtCf1Nt1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''train_seq = torch.tensor(encodings_train['input_ids'])\n",
        "val_seq = torch.tensor(encodings_val['input_ids'])\n",
        "test_seq = torch.tensor(encodings_test['input_ids'])\n",
        "\n",
        "train_mask = torch.tensor(encodings_train['attention_mask'])\n",
        "val_mask = torch.tensor(encodings_val['attention_mask'])\n",
        "test_mask = torch.tensor(encodings_test['attention_mask'])\n",
        "\n",
        "train_labels = torch.tensor(y_train.tolist())\n",
        "val_labels = torch.tensor(y_val.tolist())\n",
        "test_labels = torch.tensor(y_test.tolist())'''"
      ],
      "metadata": {
        "id": "B4nmMl0Wkz0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_tensor_train = torch.tensor(y_train.tolist())\n",
        "labels_tensor_val = torch.tensor(y_val.tolist())\n",
        "labels_tensor_test = torch.tensor(y_test.tolist())\n",
        "\n",
        "class NewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "train_ds = NewsDataset(encodings_train, y_train)\n",
        "valid_ds = NewsDataset(encodings_val, y_val)\n",
        "test_ds = NewsDataset(encodings_test, y_test)"
      ],
      "metadata": {
        "id": "PegMXsaifC89"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "qLAuj59k5XpX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVWYaGXFBlGk",
        "outputId": "1d8cd59f-3ff5-4cff-d977-892f7e640930"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "#model = BERT_architecture(model)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "FsHGUto-fzKF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-w4669s-FoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # !pip install 'accelerate>=0.26.0'"
      ],
      "metadata": {
        "id": "3FLbMIthJUag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d314f63-0d66-44ff-d31f-3cf6f18e40a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate>=0.26.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (1.7.0)\r\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.2.5)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from accelerate>=0.26.0) (24.2)\r\n",
            "Requirement already satisfied: psutil in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from accelerate>=0.26.0) (5.9.0)\r\n",
            "Requirement already satisfied: pyyaml in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from accelerate>=0.26.0) (6.0.2)\r\n",
            "Requirement already satisfied: torch>=2.0.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.7.1)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.33.0)\r\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.5.3)\r\n",
            "Requirement already satisfied: filelock in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.5.1)\r\n",
            "Requirement already satisfied: requests in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.4)\r\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.14.0)\r\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.1.3)\r\n",
            "Requirement already satisfied: setuptools in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (72.1.0)\r\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.14.0)\r\n",
            "Requirement already satisfied: networkx in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.5)\r\n",
            "Requirement already satisfied: jinja2 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\r\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.6.77)\r\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/aliuska/anaconda3/envs/my_pdp/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install transformers[torch]"
      ],
      "metadata": {
        "id": "5wSyjPN0JdTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision = precision_score(\n",
        "        labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc,\n",
        "          'precision': precision}"
      ],
      "metadata": {
        "id": "Z0xtbPKyO3Mm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./my_models',          # выходная директория\n",
        "    num_train_epochs=3,              # количество эпох\n",
        "    per_device_train_batch_size=32,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=valid_ds,\n",
        "    compute_metrics=compute_metrics     # the callback that computes metrics of interest\n",
        ") # https://huggingface.co/docs/transformers/main_classes/trainer"
      ],
      "metadata": {
        "id": "A6s8x4fC5mc_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "B-rHfrLQO3Ji",
        "outputId": "2e6eb8d3-7992-4c7b-e89e-50daf1022b11"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2928' max='2928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2928/2928 22:32, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.738700</td>\n",
              "      <td>0.650910</td>\n",
              "      <td>0.722574</td>\n",
              "      <td>0.722574</td>\n",
              "      <td>0.722574</td>\n",
              "      <td>0.722574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.561000</td>\n",
              "      <td>0.623149</td>\n",
              "      <td>0.743324</td>\n",
              "      <td>0.743324</td>\n",
              "      <td>0.743324</td>\n",
              "      <td>0.743324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.407900</td>\n",
              "      <td>0.671732</td>\n",
              "      <td>0.740826</td>\n",
              "      <td>0.740826</td>\n",
              "      <td>0.740826</td>\n",
              "      <td>0.740826</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2928, training_loss=0.5692126268897552, metrics={'train_runtime': 1353.806, 'train_samples_per_second': 69.209, 'train_steps_per_second': 2.163, 'total_flos': 6163168696860672.0, 'train_loss': 0.5692126268897552, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the current model after training\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "sNHGXYpgv2Cg",
        "outputId": "9ef512c3-0548-4f4a-c097-64ac20576b0f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='651' max='651' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [651/651 00:25]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6231492161750793,\n",
              " 'eval_accuracy': 0.7433237271853986,\n",
              " 'eval_f1': 0.7433237271853986,\n",
              " 'eval_precision': 0.7433237271853986,\n",
              " 'eval_recall': 0.7433237271853986,\n",
              " 'eval_runtime': 26.2227,\n",
              " 'eval_samples_per_second': 198.492,\n",
              " 'eval_steps_per_second': 24.826,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DY9ZuGXMIP_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device (GPU or CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Get predictions for test data\n",
        "with torch.no_grad():\n",
        "    # Move data to device and perform prediction\n",
        "    preds = model(torch.tensor(encodings_test['input_ids']).to(device), torch.tensor(encodings_test['attention_mask']).to(device))\n",
        "\n",
        "    # Move the predictions to CPU for further processing\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "\n",
        "# Convert predictions to class labels (0 or 1 for binary classification)\n",
        "pred = np.argmax(preds, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_y, pred))"
      ],
      "metadata": {
        "id": "58ayisj7yifQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3548058a-a56f-462d-ef8f-76b3eb3c3ae7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 7.77 GiB is allocated by PyTorch, and 427.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Get predictions for test data\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Move data to device and perform prediction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     preds = model(torch.tensor(encodings_test[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m]).to(device), torch.tensor(encodings_test[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m]).to(device))\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Move the predictions to CPU for further processing\u001b[39;00m\n\u001b[32m     12\u001b[39m     preds = preds.detach().cpu().numpy()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:1503\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1496\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1501\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1503\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.bert(\n\u001b[32m   1504\u001b[39m     input_ids,\n\u001b[32m   1505\u001b[39m     attention_mask=attention_mask,\n\u001b[32m   1506\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m   1507\u001b[39m     position_ids=position_ids,\n\u001b[32m   1508\u001b[39m     head_mask=head_mask,\n\u001b[32m   1509\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m   1510\u001b[39m     output_attentions=output_attentions,\n\u001b[32m   1511\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m   1512\u001b[39m     return_dict=return_dict,\n\u001b[32m   1513\u001b[39m )\n\u001b[32m   1515\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1517\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:952\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    950\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m--> \u001b[39m\u001b[32m952\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    953\u001b[39m     input_ids=input_ids,\n\u001b[32m    954\u001b[39m     position_ids=position_ids,\n\u001b[32m    955\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m    956\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m    957\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m    958\u001b[39m )\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    961\u001b[39m     attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:185\u001b[39m, in \u001b[36mBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[39m\n\u001b[32m    183\u001b[39m     position_embeddings = \u001b[38;5;28mself\u001b[39m.position_embeddings(position_ids)\n\u001b[32m    184\u001b[39m     embeddings += position_embeddings\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.LayerNorm(embeddings)\n\u001b[32m    186\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.dropout(embeddings)\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/modules/normalization.py:217\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.layer_norm(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.normalized_shape, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias, \u001b[38;5;28mself\u001b[39m.eps\n\u001b[32m    219\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/my_pdp/lib/python3.13/site-packages/torch/nn/functional.py:2910\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2900\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2901\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2902\u001b[39m         layer_norm,\n\u001b[32m   2903\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2908\u001b[39m         eps=eps,\n\u001b[32m   2909\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2910\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.layer_norm(\n\u001b[32m   2911\u001b[39m     \u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled\n\u001b[32m   2912\u001b[39m )\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 7.77 GiB is allocated by PyTorch, and 427.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bWZ6FmtUzNsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MBwrGi7zzNog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTfPxKVazNlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predict(review, Tokenizer=tokenizer, Model=model):\n",
        "    # Convert Review to a list if it's not already a list\n",
        "    if not isinstance(text, list):\n",
        "        text = [text]\n",
        "\n",
        "    Input_ids, Token_type_ids, Attention_mask = Tokenizer.batch_encode_plus(text,\n",
        "                                                                             padding=True,\n",
        "                                                                             truncation=True,\n",
        "                                                                             max_length=128,\n",
        "                                                                             return_tensors='pt').values()\n",
        "    prediction = Model.predict([Input_ids, Token_type_ids, Attention_mask])\n",
        "\n",
        "    # Use argmax along the appropriate axis to get the predicted labels\n",
        "    pred_labels = tf.argmax(prediction.logits, axis=1)\n",
        "\n",
        "    # Convert the TensorFlow tensor to a NumPy array and then to a list to get the predicted sentiment labels\n",
        "    pred_labels = [label[i] for i in pred_labels.numpy().tolist()]\n",
        "    return pred_labels"
      ],
      "metadata": {
        "id": "8p8KZ7SyHPjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"French film 'Magnificent Trip', released in 2022. It is a very touching film, in which an old lady goes with\n",
        "            a taxi driver to a nursing home. During the trip, she tells the taxi driver about both difficult life situations\n",
        "            and the most memorable moments of the 92-year-old lady's life. The film is worthy of an award, it has only\n",
        "            a few actors, but the level of acting is high, and there are also beautiful views of Paris.\"\"\"\n",
        "get_predict(text)"
      ],
      "metadata": {
        "id": "9lJPCwUVHPgR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}